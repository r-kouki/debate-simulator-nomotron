# DETAILED PROJECT EXPLICATION - DEBATE SIMULATOR NOMOTRON

> **Complete Technical Documentation**
>
> This document provides an exhaustive explanation of the Multi-Agent Debate Simulator project, with special focus on the CrewAI orchestration system. This documentation is split across multiple files for comprehensive coverage.

---

## TABLE OF CONTENTS

### This File (Main Overview)
1. [Executive Summary](#1-executive-summary)
2. [Project Overview](#2-project-overview)
3. [Complete Project Structure](#3-complete-project-structure)
4. [Technology Stack](#4-technology-stack)
5. [System Requirements](#5-system-requirements)
6. [Quick Start Guide](#6-quick-start-guide)

### Additional Documentation Files
- **[DETAILED_PROJECT_EXPLICATION_CREWAI.md](./DETAILED_PROJECT_EXPLICATION_CREWAI.md)** - Complete CrewAI System Deep-Dive
- **[DETAILED_PROJECT_EXPLICATION_BACKEND.md](./DETAILED_PROJECT_EXPLICATION_BACKEND.md)** - Python Backend Architecture
- **[DETAILED_PROJECT_EXPLICATION_FRONTEND.md](./DETAILED_PROJECT_EXPLICATION_FRONTEND.md)** - Frontend & API Documentation
- **[DETAILED_PROJECT_EXPLICATION_EXAMPLES.md](./DETAILED_PROJECT_EXPLICATION_EXAMPLES.md)** - Data Flow & Complete Examples

---

## 1. EXECUTIVE SUMMARY

### 1.1 What Is This Project?

The **Debate Simulator Nomotron** is a sophisticated multi-agent AI system that orchestrates realistic debates between AI agents. The system uses:

- **Large Language Models (LLMs)**: Specifically Llama 3.1 Nemotron Nano 8B running locally on NVIDIA GPU
- **QLoRA Fine-Tuning**: Domain-specific adapters (education, medicine, ecology, technology) for specialized knowledge
- **CrewAI Framework**: Modern agent orchestration for complex multi-step workflows
- **Dual Model Architecture**: Two independent LLM instances for Pro and Con debaters
- **RAG (Retrieval-Augmented Generation)**: Wikipedia and internet research integration
- **Windows 98-Themed Frontend**: Nostalgic React UI with draggable windows

### 1.2 Key Innovations

| Innovation | Description |
|------------|-------------|
| **Dual Model System** | Two completely separate LLM instances allow true parallel thinking - Pro and Con don't share context or bias each other |
| **Dynamic Adapter Loading** | LoRA adapters swap at runtime without reloading the base model - switch from "education" to "medicine" domain in milliseconds |
| **Quality Refinement Loops** | Research automatically refines queries if quality score < 60%, ensuring debates are well-informed |
| **8-Step Pipeline** | Structured workflow: Topic Analysis â†’ Research â†’ Classification â†’ Host Intro â†’ Debate Rounds â†’ Fact-Check â†’ Judging â†’ Guest Recommendations |
| **Aggressive Output Cleaning** | Removes all LLM artifacts (markdown, meta-commentary, instruction leakage) for natural speech |

### 1.3 Use Cases

1. **Academic Research**: Study AI argumentation, bias, and reasoning
2. **Educational Tool**: Generate balanced debates on any topic for learning
3. **Content Generation**: Create debate transcripts for media or entertainment
4. **Model Evaluation**: Compare base model vs fine-tuned adapter performance
5. **Prototype Development**: Test multi-agent architectures with real LLMs

---

## 2. PROJECT OVERVIEW

### 2.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              USER INTERFACE                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   React Frontend    â”‚  â”‚   CLI Scripts       â”‚  â”‚   REST API Client   â”‚ â”‚
â”‚  â”‚  (Windows 98 Theme) â”‚  â”‚  (run_debate_crew)  â”‚  â”‚   (Any HTTP Client) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                         â”‚                         â”‚
              â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              API LAYER                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    FastAPI Server (Python)                           â”‚   â”‚
â”‚  â”‚    /health  /debates  /topics  /profiles  /debates/:id/stream       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Alternative: Fastify Server (Node.js)                   â”‚   â”‚
â”‚  â”‚                    Uses OpenRouter for LLM calls                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CREWAI ORCHESTRATION LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         DebateCrew                                   â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚   â”‚Topic Analyst â”‚â†’ â”‚Research Agentâ”‚â†’ â”‚Research      â”‚              â”‚   â”‚
â”‚  â”‚   â”‚              â”‚  â”‚              â”‚  â”‚Analyst       â”‚              â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â”‚          â”‚                                    â”‚                      â”‚   â”‚
â”‚  â”‚          â–¼                                    â–¼                      â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚   â”‚TV Host Agent â”‚â†’ â”‚Pro Debater   â”‚â‡„ â”‚Con Debater   â”‚              â”‚   â”‚
â”‚  â”‚   â”‚              â”‚  â”‚              â”‚  â”‚              â”‚              â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â”‚                            â”‚                  â”‚                      â”‚   â”‚
â”‚  â”‚                            â–¼                  â–¼                      â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚   â”‚Fact-Check    â”‚â†’ â”‚Judge Agent   â”‚â†’ â”‚Persona Agent â”‚              â”‚   â”‚
â”‚  â”‚   â”‚Agent         â”‚  â”‚              â”‚  â”‚(Optional)    â”‚              â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            MODEL LAYER                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    DualModelManager                                  â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚   â”‚     Model Instance 1   â”‚  â”‚    Model Instance 2    â”‚            â”‚   â”‚
â”‚  â”‚   â”‚   (Pro Debater LLM)    â”‚  â”‚   (Con Debater LLM)    â”‚            â”‚   â”‚
â”‚  â”‚   â”‚                        â”‚  â”‚                        â”‚            â”‚   â”‚
â”‚  â”‚   â”‚  Base: Llama 3.1       â”‚  â”‚  Base: Llama 3.1       â”‚            â”‚   â”‚
â”‚  â”‚   â”‚  Nemotron Nano 8B      â”‚  â”‚  Nemotron Nano 8B      â”‚            â”‚   â”‚
â”‚  â”‚   â”‚                        â”‚  â”‚                        â”‚            â”‚   â”‚
â”‚  â”‚   â”‚  Adapter: education/   â”‚  â”‚  Adapter: education/   â”‚            â”‚   â”‚
â”‚  â”‚   â”‚  medicine/ecology/etc  â”‚  â”‚  medicine/ecology/etc  â”‚            â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    4-bit Quantization (QLoRA)                        â”‚   â”‚
â”‚  â”‚         ~6GB VRAM per model = ~12GB total for dual models           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          RESEARCH LAYER                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚   Wikipedia Tool     â”‚  â”‚  Internet Research   â”‚                        â”‚
â”‚  â”‚                      â”‚  â”‚  Tool (DuckDuckGo)   â”‚                        â”‚
â”‚  â”‚  - Topic summaries   â”‚  â”‚                      â”‚                        â”‚
â”‚  â”‚  - Expert search     â”‚  â”‚  - Debate facts      â”‚                        â”‚
â”‚  â”‚  - Disambiguation    â”‚  â”‚  - Pro/Con evidence  â”‚                        â”‚
â”‚  â”‚  - Caching           â”‚  â”‚  - Quality scoring   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           STORAGE LAYER                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   runs/debates/  â”‚  â”‚   data/splits/   â”‚  â”‚  models/adapters â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚                  â”‚          â”‚
â”‚  â”‚  - result.json   â”‚  â”‚  - train.jsonl   â”‚  â”‚  - education/    â”‚          â”‚
â”‚  â”‚  - transcript.txtâ”‚  â”‚  - val.jsonl     â”‚  â”‚  - medicine/     â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚  - test.jsonl    â”‚  â”‚  - ecology/      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Two Backend Options

The project supports two backend implementations:

#### Option A: Python Backend (Recommended for Local LLM)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Python Backend Stack                          â”‚
â”‚                                                                 â”‚
â”‚  FastAPI Server â†’ DebateCrew â†’ DualModelManager â†’ Local LLM    â”‚
â”‚                                                                 â”‚
â”‚  Pros:                                                          â”‚
â”‚  âœ“ Full local processing (no API costs)                        â”‚
â”‚  âœ“ QLoRA adapters for domain specialization                    â”‚
â”‚  âœ“ Complete control over model behavior                         â”‚
â”‚  âœ“ Academic evaluation ready                                    â”‚
â”‚                                                                 â”‚
â”‚  Cons:                                                          â”‚
â”‚  âœ— Requires NVIDIA GPU (10-12GB VRAM)                          â”‚
â”‚  âœ— ~1 minute initial model load time                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Option B: Node.js Backend (For Cloud LLM)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Node.js Backend Stack                         â”‚
â”‚                                                                 â”‚
â”‚  Fastify Server â†’ OpenRouter API â†’ Cloud LLM (Nemotron)        â”‚
â”‚                                                                 â”‚
â”‚  Pros:                                                          â”‚
â”‚  âœ“ No GPU required                                             â”‚
â”‚  âœ“ Instant startup                                             â”‚
â”‚  âœ“ Simpler deployment                                          â”‚
â”‚                                                                 â”‚
â”‚  Cons:                                                          â”‚
â”‚  âœ— Requires OpenRouter API key                                 â”‚
â”‚  âœ— No custom adapters                                          â”‚
â”‚  âœ— API costs for usage                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 The 8-Step Debate Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DEBATE PIPELINE FLOW                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1: TOPIC ANALYSIS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: Raw user topic ("should eletric cars be mandatory?")             â”‚
â”‚                                                                          â”‚
â”‚ Processing:                                                              â”‚
â”‚   â€¢ Grammar correction: "eletric" â†’ "electric"                          â”‚
â”‚   â€¢ Key term extraction: ["electric", "cars", "mandatory"]              â”‚
â”‚   â€¢ Domain detection: "technology" (keyword matching)                    â”‚
â”‚   â€¢ Query generation: 6 optimized search queries                         â”‚
â”‚                                                                          â”‚
â”‚ Output: TopicAnalysis object                                            â”‚
â”‚   {                                                                      â”‚
â”‚     corrected_topic: "Should electric cars be mandatory?",              â”‚
â”‚     domain_hint: "technology",                                          â”‚
â”‚     research_queries: [                                                  â”‚
â”‚       "Should electric cars be mandatory debate 2026",                  â”‚
â”‚       "electric vehicles benefits advantages",                          â”‚
â”‚       "electric cars problems concerns",                                â”‚
â”‚       ...                                                                â”‚
â”‚     ]                                                                    â”‚
â”‚   }                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
Step 2: RESEARCH GATHERING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: TopicAnalysis.research_queries                                   â”‚
â”‚                                                                          â”‚
â”‚ Processing:                                                              â”‚
â”‚   â€¢ Execute each query against Wikipedia API                            â”‚
â”‚   â€¢ Execute each query against DuckDuckGo (if use_internet=True)        â”‚
â”‚   â€¢ Apply quality scoring to results                                    â”‚
â”‚   â€¢ If score < 60: refine query and retry (max 5 attempts)              â”‚
â”‚   â€¢ Cache results per-session (MD5 hash keys)                           â”‚
â”‚                                                                          â”‚
â”‚ Output: Raw research context (concatenated text)                        â”‚
â”‚   "Electric vehicles (EVs) are automobiles that use one or more         â”‚
â”‚    electric motors for propulsion... According to IEA data, EV sales    â”‚
â”‚    increased by 35% in 2025... Critics argue that battery production    â”‚
â”‚    has significant environmental impact..."                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
Step 3: RESEARCH CLASSIFICATION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: Raw research context + topic                                     â”‚
â”‚                                                                          â”‚
â”‚ Processing:                                                              â”‚
â”‚   â€¢ Identify PRO indicators: "benefit", "advantage", "positive"         â”‚
â”‚   â€¢ Identify CON indicators: "problem", "risk", "negative", "concern"   â”‚
â”‚   â€¢ Extract statistics: numbers + units (%, million, billion)           â”‚
â”‚   â€¢ Extract key facts: "according to", "research shows"                 â”‚
â”‚   â€¢ Calculate quality score (0-100)                                     â”‚
â”‚                                                                          â”‚
â”‚ Output: ClassifiedResearch object                                       â”‚
â”‚   {                                                                      â”‚
â”‚     pro_points: [                                                        â”‚
â”‚       "EVs produce zero direct emissions",                              â”‚
â”‚       "Lower lifetime operating costs",                                 â”‚
â”‚       "35% sales growth indicates market demand"                        â”‚
â”‚     ],                                                                   â”‚
â”‚     con_points: [                                                        â”‚
â”‚       "Battery production has environmental impact",                    â”‚
â”‚       "Charging infrastructure gaps in rural areas",                    â”‚
â”‚       "Higher upfront purchase cost"                                    â”‚
â”‚     ],                                                                   â”‚
â”‚     statistics: ["35% growth", "80% lower fuel costs"],                 â”‚
â”‚     quality_score: 78                                                   â”‚
â”‚   }                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
Step 4: TV HOST INTRODUCTION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: Topic + classified research                                      â”‚
â”‚                                                                          â”‚
â”‚ Processing:                                                              â”‚
â”‚   â€¢ Generate engaging opening (TV debate style)                         â”‚
â”‚   â€¢ List 3-5 key questions for the debate                               â”‚
â”‚   â€¢ Set the stage for both sides                                        â”‚
â”‚                                                                          â”‚
â”‚ Output: DebateIntroduction object                                       â”‚
â”‚   {                                                                      â”‚
â”‚     opening: "Good evening! Tonight we tackle a question that affects   â”‚
â”‚               every driver on the road: Should electric cars be         â”‚
â”‚               mandatory? With climate change accelerating and EV        â”‚
â”‚               technology advancing rapidly, this debate couldn't be     â”‚
â”‚               more timely...",                                           â”‚
â”‚     key_questions: [                                                     â”‚
â”‚       "Can the grid handle universal EV adoption?",                     â”‚
â”‚       "What about rural communities without charging infrastructure?",  â”‚
â”‚       "Is the environmental benefit real when considering batteries?"   â”‚
â”‚     ]                                                                    â”‚
â”‚   }                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
Step 5: DEBATE ROUNDS (repeated N times)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each round (1 to num_rounds):                                       â”‚
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ PRO DEBATER (Model Instance 1)                                   â”‚   â”‚
â”‚   â”‚                                                                   â”‚   â”‚
â”‚   â”‚ Input:                                                            â”‚   â”‚
â”‚   â”‚   â€¢ Topic                                                         â”‚   â”‚
â”‚   â”‚   â€¢ Pro-specific research context                                 â”‚   â”‚
â”‚   â”‚   â€¢ Opponent's last argument (if round > 1)                       â”‚   â”‚
â”‚   â”‚   â€¢ Round number (affects opening vs rebuttal prompts)            â”‚   â”‚
â”‚   â”‚                                                                   â”‚   â”‚
â”‚   â”‚ Processing:                                                       â”‚   â”‚
â”‚   â”‚   â€¢ Load domain adapter (education, medicine, etc.)               â”‚   â”‚
â”‚   â”‚   â€¢ Generate argument using debate_tool._run()                    â”‚   â”‚
â”‚   â”‚   â€¢ Clean output (remove markdown, meta-commentary)               â”‚   â”‚
â”‚   â”‚   â€¢ Limit to 10 sentences max                                     â”‚   â”‚
â”‚   â”‚                                                                   â”‚   â”‚
â”‚   â”‚ Output: Pro argument string (5-10 sentences)                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                          â”‚
â”‚                              â–¼                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ CON DEBATER (Model Instance 2)                                   â”‚   â”‚
â”‚   â”‚                                                                   â”‚   â”‚
â”‚   â”‚ Input:                                                            â”‚   â”‚
â”‚   â”‚   â€¢ Topic                                                         â”‚   â”‚
â”‚   â”‚   â€¢ Con-specific research context                                 â”‚   â”‚
â”‚   â”‚   â€¢ Pro's argument from this round (added to history)             â”‚   â”‚
â”‚   â”‚   â€¢ Round number                                                  â”‚   â”‚
â”‚   â”‚                                                                   â”‚   â”‚
â”‚   â”‚ Processing:                                                       â”‚   â”‚
â”‚   â”‚   â€¢ Same as Pro, but with Con-specific prompts                    â”‚   â”‚
â”‚   â”‚   â€¢ Explicitly addresses Pro's claims                             â”‚   â”‚
â”‚   â”‚                                                                   â”‚   â”‚
â”‚   â”‚ Output: Con argument string (5-10 sentences)                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚ History updated after each turn for next round's context                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
Step 6: FACT-CHECKING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: All pro_arguments[], all con_arguments[], research_context       â”‚
â”‚                                                                          â”‚
â”‚ Processing (for each side):                                             â”‚
â”‚   â€¢ Extract claims (sentences with 5+ words)                            â”‚
â”‚   â€¢ For each claim:                                                      â”‚
â”‚     - Tokenize into words, remove stopwords                             â”‚
â”‚     - Calculate word overlap with research (Jaccard-like)               â”‚
â”‚     - Score: overlap/max(len(claim_words), len(research_words))         â”‚
â”‚   â€¢ Aggregate scores:                                                    â”‚
â”‚     - avg_support_score = mean of all claim scores                      â”‚
â”‚     - faithfulness_score = supported_claims / total_claims              â”‚
â”‚                                                                          â”‚
â”‚ Output: Fact-check results                                              â”‚
â”‚   {                                                                      â”‚
â”‚     "pro": {                                                             â”‚
â”‚       "num_claims": 8,                                                   â”‚
â”‚       "supported_claims": 6,                                             â”‚
â”‚       "faithfulness_score": 0.75,                                        â”‚
â”‚       "verdict": "well_supported"                                        â”‚
â”‚     },                                                                   â”‚
â”‚     "con": {                                                             â”‚
â”‚       "num_claims": 7,                                                   â”‚
â”‚       "supported_claims": 4,                                             â”‚
â”‚       "faithfulness_score": 0.57,                                        â”‚
â”‚       "verdict": "partially_supported"                                   â”‚
â”‚     }                                                                    â”‚
â”‚   }                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
Step 7: JUDGING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: pro_arguments[], con_arguments[], fact_check_results             â”‚
â”‚                                                                          â”‚
â”‚ Processing:                                                              â”‚
â”‚   For each argument, calculate 4 scores (0-25 each):                    â”‚
â”‚                                                                          â”‚
â”‚   LENGTH (0-25):                                                        â”‚
â”‚     â€¢ word_count = len(argument.split())                                â”‚
â”‚     â€¢ score = min(25, word_count * 25 / 100)                            â”‚
â”‚                                                                          â”‚
â”‚   LOGIC (0-25):                                                         â”‚
â”‚     â€¢ Count logical markers: "because", "therefore", "thus",            â”‚
â”‚       "consequently", "since", "as a result"                            â”‚
â”‚     â€¢ score = min(25, marker_count * 5)                                 â”‚
â”‚                                                                          â”‚
â”‚   EVIDENCE (0-25):                                                      â”‚
â”‚     â€¢ Count evidence markers: "study", "research", "data",              â”‚
â”‚       "percent", "%", "according to", "expert"                          â”‚
â”‚     â€¢ score = min(25, evidence_count * 5)                               â”‚
â”‚                                                                          â”‚
â”‚   CIVILITY (0-25):                                                      â”‚
â”‚     â€¢ Start with 25, subtract for aggressive language                   â”‚
â”‚     â€¢ Deductions: "stupid", "idiot", "nonsense", "ridiculous"           â”‚
â”‚     â€¢ score = max(0, 25 - deductions)                                   â”‚
â”‚                                                                          â”‚
â”‚   TOTAL = LENGTH + LOGIC + EVIDENCE + CIVILITY                          â”‚
â”‚   AVERAGE = sum(all argument totals) / num_arguments                    â”‚
â”‚                                                                          â”‚
â”‚   FINAL SCORE (with fact-check weight):                                 â”‚
â”‚     final = average * 0.7 + (faithfulness_score * 100) * 0.3            â”‚
â”‚                                                                          â”‚
â”‚   WINNER DETERMINATION:                                                 â”‚
â”‚     â€¢ If |pro_final - con_final| < 3: TIE                               â”‚
â”‚     â€¢ Else: higher score wins                                           â”‚
â”‚                                                                          â”‚
â”‚ Output: JudgeScore object                                               â”‚
â”‚   {                                                                      â”‚
â”‚     pro_score: 78,                                                       â”‚
â”‚     con_score: 72,                                                       â”‚
â”‚     winner: "pro",                                                       â”‚
â”‚     reasoning: "Pro wins with stronger evidence citations and           â”‚
â”‚                 higher fact-check faithfulness (0.75 vs 0.57).          â”‚
â”‚                 Con made compelling points but lacked specific data."   â”‚
â”‚   }                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
Step 8: GUEST RECOMMENDATIONS (Optional)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: Topic, domain, wikipedia_tool, internet_tool                     â”‚
â”‚                                                                          â”‚
â”‚ Processing:                                                              â”‚
â”‚   â€¢ Generate expert search queries:                                      â”‚
â”‚     - "[domain] expert [topic]"                                         â”‚
â”‚     - "[topic] professor researcher"                                    â”‚
â”‚     - "[topic] advocate critic"                                         â”‚
â”‚   â€¢ Search Wikipedia for notable people                                 â”‚
â”‚   â€¢ Cross-reference with web search                                     â”‚
â”‚   â€¢ Filter to ensure real people (not events/concepts)                  â”‚
â”‚   â€¢ Validate with bio indicators: "born", "is a", "professor"           â”‚
â”‚                                                                          â”‚
â”‚ Output: List of DebateGuest objects                                     â”‚
â”‚   [                                                                      â”‚
â”‚     {                                                                    â”‚
â”‚       name: "Mary Nichols",                                             â”‚
â”‚       title: "Former Chair, California Air Resources Board",            â”‚
â”‚       expertise: "EV policy and emissions regulation",                  â”‚
â”‚       relevance: "Key architect of California's EV mandate"             â”‚
â”‚     },                                                                   â”‚
â”‚     {                                                                    â”‚
â”‚       name: "Sandy Munro",                                              â”‚
â”‚       title: "Automotive Engineer and Analyst",                         â”‚
â”‚       expertise: "EV manufacturing and teardown analysis",              â”‚
â”‚       relevance: "Provides detailed cost/quality comparisons"           â”‚
â”‚     },                                                                   â”‚
â”‚     ...                                                                  â”‚
â”‚   ]                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. COMPLETE PROJECT STRUCTURE

```
debate-simulator-nomotron/
â”‚
â”œâ”€â”€ ğŸ“ src/                                    # Python backend source code
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ crew/                               # â˜… CREWAI SYSTEM (Main Focus) â˜…
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ debate_crew.py                  # Main orchestrator (568 lines)
â”‚   â”‚   â”‚   â””â”€â”€ DebateCrew class
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__()                 # Initialize with settings
â”‚   â”‚   â”‚       â”œâ”€â”€ run_debate()               # Execute full 8-step pipeline
â”‚   â”‚   â”‚       â”œâ”€â”€ _gather_research_with_queries()
â”‚   â”‚   â”‚       â”œâ”€â”€ _generate_argument()       # Single argument generation
â”‚   â”‚   â”‚       â”œâ”€â”€ _fact_check_debate()       # Verify claims
â”‚   â”‚   â”‚       â””â”€â”€ _save_artifacts()          # Persist results
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ teacher_crew.py                 # Educational mode (120 lines)
â”‚   â”‚   â”‚   â””â”€â”€ TeacherCrew class
â”‚   â”‚   â”‚       â”œâ”€â”€ teach()                    # Generate structured lesson
â”‚   â”‚   â”‚       â””â”€â”€ _generate_lesson()         # LLM-based content
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ agents/                         # CrewAI Agent Definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ topic_analyst.py            # Grammar + query optimization
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TopicAnalysis dataclass
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ GRAMMAR_CORRECTIONS dict
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DOMAIN_KEYWORDS dict
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ analyze_topic() function
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ research_agent.py           # Wikipedia + Internet coordination
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ResearchAgent class
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ research_analyst.py         # PRO/CON classification
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ClassifiedResearch dataclass
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ analyze_research() function
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ router_agent.py             # Domain classification
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DOMAIN_KEYWORDS dict
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ create_router_agent() function
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ debater_agents.py           # Pro/Con argument generators
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ create_pro_debater_agent()
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ create_con_debater_agent()
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ factcheck_agent.py          # Claim verification
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ STOPWORDS set
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ compute_faithfulness_score()
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ create_factcheck_agent()
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ judge_agent.py              # Scoring + winner determination
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ JudgeScore dataclass
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ judge_debate() function
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ _score_argument() helper
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ persona_agent.py            # Expert recommendations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DebateGuest dataclass
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ recommend_debate_guests()
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ _is_real_person() validator
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ tv_host_agent.py            # Debate introduction
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DebateIntroduction dataclass
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ generate_tv_host_introduction()
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ teacher_agent.py            # Lesson generation
â”‚   â”‚   â”‚       â”œâ”€â”€ Lesson dataclass
â”‚   â”‚   â”‚       â””â”€â”€ create_teacher_agent()
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ tools/                          # CrewAI Tool Implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ debate_tool.py              # Argument generation (432 lines)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DebateTurn dataclass
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DebateGenerationTool class
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _run()                 # Main generation method
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _build_prompt()        # Opening vs rebuttal
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _clean_output()        # Remove LLM artifacts
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ add_external_turn()    # History management
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ OPENING_PROMPT, REBUTTAL_PROMPT templates
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ internet_research.py        # Web search with caching
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ InternetResearchTool class
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _run()                 # Execute search
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _search_debate()       # Debate-focused search
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ _search_debate_with_refinement()
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Session caching (MD5 keys)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ wikipedia_tool.py           # Wikipedia access
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ WikipediaSearchTool class
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _run()                 # Execute query
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ search_type: summary/experts/full
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Disambiguation handling
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ research_evaluator.py       # Quality scoring
â”‚   â”‚   â”‚       â”œâ”€â”€ ResearchEvaluation dataclass
â”‚   â”‚   â”‚       â”œâ”€â”€ evaluate_research_quality()
â”‚   â”‚   â”‚       â”œâ”€â”€ ISSUE_CATEGORIES dict
â”‚   â”‚   â”‚       â””â”€â”€ Scoring rubric (0-100)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ utils/
â”‚   â”‚       â””â”€â”€ ğŸ“„ dual_model_manager.py       # Two LLM instances (277 lines)
â”‚   â”‚           â”œâ”€â”€ DualModelManager class
â”‚   â”‚           â”‚   â”œâ”€â”€ model_pro property     # Lazy-loaded Pro model
â”‚   â”‚           â”‚   â”œâ”€â”€ model_con property     # Lazy-loaded Con model
â”‚   â”‚           â”‚   â”œâ”€â”€ load_adapter()         # Dynamic adapter loading
â”‚   â”‚           â”‚   â”œâ”€â”€ generate_pro()         # Pro generation
â”‚   â”‚           â”‚   â”œâ”€â”€ generate_con()         # Con generation
â”‚   â”‚           â”‚   â””â”€â”€ get_memory_stats()     # VRAM usage
â”‚   â”‚           â””â”€â”€ Adapter path management
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ agents/                             # Original multi-agent system (legacy)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ base.py                         # Agent ABC + state machine
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentState enum
â”‚   â”‚   â”‚   â”œâ”€â”€ DebateTurn dataclass
â”‚   â”‚   â”‚   â”œâ”€â”€ JudgeScore dataclass
â”‚   â”‚   â”‚   â”œâ”€â”€ DebateContext dataclass
â”‚   â”‚   â”‚   â””â”€â”€ Agent abstract class
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ router.py                       # DomainRouterAgent
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ research.py                     # ResearchAgent (BM25)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ debater.py                      # DebaterAgent
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ factcheck.py                    # FactCheckAgent
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ judge.py                        # JudgeAgent
â”‚   â”‚   â””â”€â”€ ğŸ“„ logger.py                       # LoggerAgent
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ orchestration/
â”‚   â”‚   â””â”€â”€ ğŸ“„ pipeline.py                     # DebatePipeline state machine
â”‚   â”‚       â”œâ”€â”€ DebatePipeline class
â”‚   â”‚       â”‚   â”œâ”€â”€ run()                      # Main execution loop
â”‚   â”‚       â”‚   â”œâ”€â”€ _transition()              # State transitions
â”‚   â”‚       â”‚   â””â”€â”€ _process_state()           # Per-state logic
â”‚   â”‚       â””â”€â”€ State flow: ROUTING â†’ ... â†’ COMPLETE
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ serving/                            # FastAPI server
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ api.py                          # REST endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ /health
â”‚   â”‚   â”‚   â”œâ”€â”€ /topics/search
â”‚   â”‚   â”‚   â”œâ”€â”€ /topics/{topic_id}
â”‚   â”‚   â”‚   â”œâ”€â”€ /debates (POST)
â”‚   â”‚   â”‚   â”œâ”€â”€ /debates/{id}/next-turn (POST)
â”‚   â”‚   â”‚   â”œâ”€â”€ /debates/{id}/turns (POST)
â”‚   â”‚   â”‚   â”œâ”€â”€ /debates/{id}/turns/stream (POST) - SSE
â”‚   â”‚   â”‚   â””â”€â”€ /debates/{id}/score (POST)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ models.py                       # Pydantic schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ StartDebateRequest
â”‚   â”‚   â”‚   â”œâ”€â”€ StartDebateResponse
â”‚   â”‚   â”‚   â”œâ”€â”€ SendTurnRequest
â”‚   â”‚   â”‚   â”œâ”€â”€ SendTurnResponse
â”‚   â”‚   â”‚   â””â”€â”€ ScoreDebateResponse
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ debate_service.py               # Session management
â”‚   â”‚   â”‚   â”œâ”€â”€ DebateSession dataclass
â”‚   â”‚   â”‚   â””â”€â”€ DebateService class
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ profile.py                      # User profile storage
â”‚   â”‚   â”‚   â””â”€â”€ JSON-based persistence
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ topics.py                       # Topic database
â”‚   â”‚       â””â”€â”€ TopicSearchService class
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ train/                              # Training pipeline
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ dataset.py                      # JSONL loading
â”‚   â”‚   â”‚   â”œâ”€â”€ load_dataset()
â”‚   â”‚   â”‚   â””â”€â”€ tokenize_dataset()
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ trainer.py                      # QLoRA training
â”‚   â”‚       â”œâ”€â”€ TrainingMetrics dataclass
â”‚   â”‚       â”œâ”€â”€ MetricsCallback class
â”‚   â”‚       â””â”€â”€ get_training_arguments()
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/
â”‚       â”œâ”€â”€ ğŸ“„ model_loader.py                 # Model loading utilities
â”‚       â”‚   â”œâ”€â”€ get_bnb_config()               # 4-bit quantization
â”‚       â”‚   â”œâ”€â”€ get_lora_config()              # LoRA hyperparameters
â”‚       â”‚   â”œâ”€â”€ load_base_model()              # Load Llama 3.1 Nemotron
â”‚       â”‚   â”œâ”€â”€ load_model_with_adapter()      # Load with LoRA
â”‚       â”‚   â””â”€â”€ prepare_model_for_training()   # Add LoRA layers
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“„ web_search.py                   # DuckDuckGo wrapper
â”‚
â”œâ”€â”€ ğŸ“ frontend/                               # React + TypeScript + Vite
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ api/                            # API layer
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ adapters/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mock.ts                    # Mock API for testing
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ openRouter.ts              # OpenRouter integration
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ hooks/                      # React Query hooks
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ useHealth.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ useStartDebate.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ useNextTurn.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ useSendTurn.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ useScoreDebate.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ useTopics.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ useProfile.ts
â”‚   â”‚   â”‚   â””â”€â”€ client.ts                      # Base API client
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/                     # UI Components
â”‚   â”‚   â”‚   â”œâ”€â”€ WindowFrame.tsx                # Draggable windows
â”‚   â”‚   â”‚   â”œâ”€â”€ Taskbar.tsx                    # Bottom bar
â”‚   â”‚   â”‚   â”œâ”€â”€ StartMenu.tsx                  # Windows menu
â”‚   â”‚   â”‚   â”œâ”€â”€ Desktop.tsx                    # Main canvas
â”‚   â”‚   â”‚   â”œâ”€â”€ ContextMenu.tsx                # Right-click menus
â”‚   â”‚   â”‚   â”œâ”€â”€ DialogHost.tsx                 # Modal dialogs
â”‚   â”‚   â”‚   â”œâ”€â”€ Tabs.tsx                       # Tab navigation
â”‚   â”‚   â”‚   â””â”€â”€ ToastContainer.tsx             # Notifications
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ features/                       # Feature modules
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ debate/                     # Debate UI
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ topics/                     # Topic browser
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ profile/                    # User profile
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ settings/                   # Settings panel
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ state/                          # Zustand stores
â”‚   â”‚       â”œâ”€â”€ windowStore.ts                 # Window management
â”‚   â”‚       â”œâ”€â”€ debateStore.ts                 # Debate state
â”‚   â”‚       â”œâ”€â”€ settingsStore.ts               # User preferences
â”‚   â”‚       â””â”€â”€ profileStore.ts                # Player profile
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ apps/api/                           # Optional Node.js backend
â”‚   â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ routes/                     # Fastify routes
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ health.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ profile.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ topics.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ debates.ts
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ agents/                     # Simplified agents
â”‚   â”‚   â”‚       â”œâ”€â”€ researchAgent.ts
â”‚   â”‚   â”‚       â”œâ”€â”€ debaterAgent.ts
â”‚   â”‚   â”‚       â””â”€â”€ judgeAgent.ts
â”‚   â”‚   â””â”€â”€ ğŸ“ prisma/                         # Database schema
â”‚   â”‚       â””â”€â”€ schema.prisma                  # SQLite schema
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ packages/contracts/                 # Shared schemas
â”‚       â””â”€â”€ ğŸ“ src/
â”‚           â””â”€â”€ index.ts                       # Zod schemas
â”‚
â”œâ”€â”€ ğŸ“ scripts/                                # Executable Python scripts
â”‚   â”œâ”€â”€ ğŸ“„ run_debate_crew.py                  # â˜… Main CLI entry point â˜…
â”‚   â”œâ”€â”€ ğŸ“„ run_debate.py                       # Legacy debate script
â”‚   â”œâ”€â”€ ğŸ“„ run_server.py                       # FastAPI server
â”‚   â”œâ”€â”€ ğŸ“„ run_teacher.py                      # Teacher crew CLI
â”‚   â”œâ”€â”€ ğŸ“„ verify_base_model.py                # Model loading test
â”‚   â”œâ”€â”€ ğŸ“„ generate_education_dataset.py       # Dataset generation
â”‚   â”œâ”€â”€ ğŸ“„ train_education_adapter.py          # QLoRA training
â”‚   â”œâ”€â”€ ğŸ“„ evaluate_education_adapter.py       # Adapter evaluation
â”‚   â””â”€â”€ ğŸ“„ generate_academic_report.py         # Report generation
â”‚
â”œâ”€â”€ ğŸ“ models/                                 # Model storage
â”‚   â”œâ”€â”€ ğŸ“ base/
â”‚   â”‚   â””â”€â”€ ğŸ“ llama3.1-nemotron-nano-8b-v1/   # Base LLM (~8GB)
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ model.safetensors
â”‚   â”‚       â”œâ”€â”€ tokenizer.json
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ adapters/                           # LoRA adapters (~2-4MB each)
â”‚       â”œâ”€â”€ ğŸ“ education/
â”‚       â”‚   â”œâ”€â”€ adapter_config.json
â”‚       â”‚   â””â”€â”€ adapter_model.safetensors
â”‚       â”œâ”€â”€ ğŸ“ medicine/
â”‚       â”œâ”€â”€ ğŸ“ ecology/
â”‚       â”œâ”€â”€ ğŸ“ technology/
â”‚       â””â”€â”€ ğŸ“ debate/
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ ğŸ“ splits/                             # Training datasets
â”‚   â”‚   â”œâ”€â”€ ğŸ“ education/
â”‚   â”‚   â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”‚   â”‚   â”œâ”€â”€ val.jsonl
â”‚   â”‚   â”‚   â””â”€â”€ test.jsonl
â”‚   â”‚   â”œâ”€â”€ ğŸ“ medicine/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ğŸ“ profiles/                           # User profiles
â”‚   â””â”€â”€ ğŸ“ cache/                              # HuggingFace cache
â”‚
â”œâ”€â”€ ğŸ“ runs/                                   # Output artifacts
â”‚   â”œâ”€â”€ ğŸ“ train/                              # Training checkpoints
â”‚   â”œâ”€â”€ ğŸ“ eval/                               # Evaluation results
â”‚   â”œâ”€â”€ ğŸ“ debates/                            # Debate transcripts
â”‚   â”‚   â””â”€â”€ ğŸ“ {timestamp}_{topic}/
â”‚   â”‚       â”œâ”€â”€ result.json
â”‚   â”‚       â””â”€â”€ transcript.txt
â”‚   â””â”€â”€ ğŸ“ reports/                            # Academic reports
â”‚
â”œâ”€â”€ ğŸ“ configs/                                # Configuration files
â”‚   â””â”€â”€ training_config.yaml
â”‚
â”œâ”€â”€ ğŸ“ test_outputs/                           # Test results
â”‚   â””â”€â”€ STANDALONE_TEST_SUMMARY.md
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt                        # Python dependencies
â”œâ”€â”€ ğŸ“„ CLAUDE.md                               # Project instructions
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md                         # System design
â”œâ”€â”€ ğŸ“„ Dockerfile.backend                      # Backend container
â”œâ”€â”€ ğŸ“„ Dockerfile.frontend                     # Frontend container
â”œâ”€â”€ ğŸ“„ docker-compose.yml                      # Multi-container setup
â””â”€â”€ ğŸ“„ nginx.conf                              # Reverse proxy config
```

---

## 4. TECHNOLOGY STACK

### 4.1 Python Backend

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **LLM Framework** | Transformers | 4.x | Model loading and inference |
| **Quantization** | BitsAndBytes | 0.x | 4-bit quantization (QLoRA) |
| **Fine-tuning** | PEFT | 0.x | LoRA adapter training |
| **Agent Framework** | CrewAI | 1.8.0 | Multi-agent orchestration |
| **Web Framework** | FastAPI | 0.x | REST API server |
| **Async Runtime** | Uvicorn | 0.x | ASGI server |
| **Validation** | Pydantic | 2.x | Request/response schemas |
| **ML Compute** | PyTorch | 2.x | Tensor operations |
| **CUDA** | NVIDIA CUDA | 12.x | GPU acceleration |

### 4.2 Frontend

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **Framework** | React | 18.x | UI components |
| **Language** | TypeScript | 5.x | Type safety |
| **Build Tool** | Vite | 5.x | Fast development |
| **State Management** | Zustand | 4.x | Global state |
| **Data Fetching** | React Query | 5.x | API caching |
| **Styling** | CSS Modules | - | Scoped styles |
| **Testing** | Vitest | 1.x | Unit tests |
| **Linting** | ESLint | 8.x | Code quality |

### 4.3 Node.js Backend (Alternative)

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **Framework** | Fastify | 4.x | High-performance HTTP |
| **Database** | Prisma + SQLite | 5.x | Data persistence |
| **LLM API** | OpenRouter | - | Cloud LLM access |
| **Validation** | Zod | 3.x | Schema validation |

### 4.4 DevOps

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Containers** | Docker | Reproducible builds |
| **Orchestration** | Docker Compose | Multi-service setup |
| **Reverse Proxy** | Nginx | Load balancing |

---

## 5. SYSTEM REQUIREMENTS

### 5.1 Hardware Requirements

#### Minimum (Inference Only)
- **GPU**: NVIDIA with 8GB VRAM (RTX 3070, RTX 4060)
- **RAM**: 16GB system memory
- **Storage**: 20GB free space
- **CPU**: Any modern 4-core processor

#### Recommended (Full Dual Model)
- **GPU**: NVIDIA with 12GB+ VRAM (RTX 3090, RTX 4080, RTX 4090)
- **RAM**: 32GB system memory
- **Storage**: 50GB free space (models + datasets + outputs)
- **CPU**: 8-core processor recommended

#### Training Requirements
- **GPU**: NVIDIA with 16GB+ VRAM
- **RAM**: 64GB system memory recommended
- **Storage**: 100GB+ for checkpoints

### 5.2 Software Requirements

```bash
# Operating System
- Linux (Ubuntu 22.04+ recommended)
- Windows 11 with WSL2
- macOS (CPU-only, no training)

# Python
- Python 3.12+
- pip or conda

# CUDA
- CUDA Toolkit 12.x
- cuDNN 8.x

# Node.js (for frontend)
- Node.js 18+
- npm 9+

# Git
- Git 2.x
```

### 5.3 VRAM Usage Breakdown

| Configuration | VRAM Usage | Notes |
|---------------|------------|-------|
| Single model (inference) | ~6 GB | 4-bit quantized |
| Dual models (inference) | ~12 GB | Pro + Con instances |
| Single model + training | ~10 GB | Gradient checkpointing |
| Full training | ~16 GB | No gradient checkpointing |

---

## 6. QUICK START GUIDE

### 6.1 Installation

```bash
# Clone repository
git clone <repository-url>
cd debate-simulator-nomotron

# Create Python virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# or: .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Verify GPU access
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# Verify base model loads
python scripts/verify_base_model.py
```

### 6.2 Running a Debate (CLI)

```bash
# Simple debate (2 rounds, no internet)
python scripts/run_debate_crew.py "Should college be free?"

# Full-featured debate
python scripts/run_debate_crew.py \
  "Should artificial intelligence be regulated?" \
  --rounds 3 \
  --use-internet \
  --recommend-guests

# Quiet mode (less output)
python scripts/run_debate_crew.py "Your topic" --quiet
```

### 6.3 Running the Web Application

```bash
# Terminal 1: Start Python API server
python scripts/run_server.py

# Terminal 2: Start frontend
cd frontend
npm install
npm run dev

# Open browser: http://localhost:5173
```

### 6.4 Training a Custom Adapter

```bash
# Generate training dataset
python scripts/generate_education_dataset.py

# Train adapter (adjust epochs/batch size for your VRAM)
python scripts/train_education_adapter.py

# Evaluate adapter vs base model
python scripts/evaluate_education_adapter.py

# Generate report with visualizations
python scripts/generate_academic_report.py
```

---

## NEXT: CrewAI Deep-Dive

Continue to **[DETAILED_PROJECT_EXPLICATION_CREWAI.md](./DETAILED_PROJECT_EXPLICATION_CREWAI.md)** for complete documentation of:

- DebateCrew class internals
- DualModelManager implementation
- All 11 CrewAI agents in detail
- All 4 CrewAI tools in detail
- Prompt engineering techniques
- Output cleaning algorithms
- Quality refinement loops

---

*Generated: 2026-01-11*
*Project: Debate Simulator Nomotron*
