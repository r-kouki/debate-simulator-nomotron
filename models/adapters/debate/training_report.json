{
  "timestamp": "2026-01-06T00:42:24.973390",
  "config": {
    "domain": "debate",
    "base_model": "/home/core/projects/debate-simulator/models/base/llama3.1-nemotron-nano-8b-v1",
    "sft_path": "data/sft/debate_improved.jsonl",
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05,
    "target_modules": [
      "q_proj",
      "v_proj"
    ],
    "num_epochs": 2,
    "batch_size": 2,
    "gradient_accumulation_steps": 8,
    "learning_rate": 0.0002,
    "max_seq_length": 512,
    "max_train_samples": 4000,
    "max_val_samples": 400,
    "max_test_samples": 200
  },
  "dataset_sizes": {
    "train": 4000,
    "val": 400,
    "test": 200
  },
  "final_metrics": {
    "train_loss": 1.6502563915252686,
    "train_perplexity": 5.208315023839022,
    "val_loss": 1.4102227687835693,
    "val_perplexity": 4.096867956714442,
    "test_loss": 1.432015061378479,
    "test_perplexity": 4.18712801672475
  },
  "training_history": {
    "steps": [
      5,
      10,
      15,
      20,
      25,
      30,
      35,
      40,
      45,
      50,
      55,
      60,
      65,
      70,
      75,
      80,
      85,
      90,
      95,
      100,
      105,
      110,
      115,
      120,
      125,
      130,
      135,
      140,
      145,
      150,
      155,
      160,
      165,
      170,
      175,
      180,
      185,
      190,
      195,
      200,
      205,
      210,
      215,
      220,
      225,
      230,
      235,
      240,
      245,
      250,
      255,
      260,
      265,
      270,
      275,
      280,
      285,
      290,
      295,
      300,
      305,
      310,
      315,
      320,
      325,
      330,
      335,
      340,
      345,
      350,
      355,
      360,
      365,
      370,
      375,
      380,
      385,
      390,
      395,
      400,
      405,
      410,
      415,
      420,
      425,
      430,
      435,
      440,
      445,
      450,
      455,
      460,
      465,
      470,
      475,
      480,
      485,
      490,
      495,
      500
    ],
    "training_loss": [
      4.3076,
      4.1906,
      4.0307,
      3.795,
      3.373,
      3.0522,
      2.6421,
      2.249,
      2.0311,
      1.8454,
      1.8042,
      1.7306,
      1.6923,
      1.6253,
      1.607,
      1.6198,
      1.6929,
      1.5948,
      1.6613,
      1.6243,
      1.5696,
      1.5756,
      1.5161,
      1.5709,
      1.625,
      1.6029,
      1.5943,
      1.6308,
      1.5808,
      1.5634,
      1.5721,
      1.5594,
      1.5601,
      1.5196,
      1.5015,
      1.582,
      1.5616,
      1.5304,
      1.5361,
      1.5139,
      1.5423,
      1.4907,
      1.5103,
      1.4647,
      1.4595,
      1.4736,
      1.4895,
      1.5164,
      1.4784,
      1.4643,
      1.4245,
      1.4027,
      1.4795,
      1.428,
      1.4708,
      1.4408,
      1.447,
      1.4398,
      1.383,
      1.432,
      1.412,
      1.4154,
      1.4104,
      1.3656,
      1.385,
      1.3932,
      1.4249,
      1.4587,
      1.451,
      1.4111,
      1.4272,
      1.4175,
      1.4201,
      1.402,
      1.4663,
      1.3592,
      1.3879,
      1.4222,
      1.4155,
      1.4503,
      1.388,
      1.385,
      1.3954,
      1.3595,
      1.3909,
      1.4312,
      1.4072,
      1.4833,
      1.3818,
      1.4111,
      1.3908,
      1.3656,
      1.3651,
      1.3666,
      1.3954,
      1.4174,
      1.4574,
      1.4358,
      1.4269,
      1.4031
    ],
    "validation_loss": [
      3.62503719329834,
      2.0786828994750977,
      1.6658700704574585,
      1.6108386516571045,
      1.5888302326202393,
      1.5733275413513184,
      1.5590896606445312,
      1.546056866645813,
      1.533759593963623,
      1.519016146659851,
      1.4911935329437256,
      1.4701275825500488,
      1.461201786994934,
      1.447757601737976,
      1.4392027854919434,
      1.4343510866165161,
      1.4299712181091309,
      1.4271742105484009,
      1.4207961559295654,
      1.4206088781356812,
      1.4161176681518555,
      1.4132781028747559,
      1.4123034477233887,
      1.4104119539260864,
      1.4102227687835693,
      1.4102227687835693,
      1.432015061378479
    ],
    "learning_rate": [
      1.6000000000000003e-05,
      3.6e-05,
      5.6000000000000006e-05,
      7.6e-05,
      9.6e-05,
      0.000116,
      0.00013600000000000003,
      0.00015600000000000002,
      0.00017600000000000002,
      0.000196,
      0.00019822222222222225,
      0.000196,
      0.0001937777777777778,
      0.00019155555555555554,
      0.00018933333333333335,
      0.00018711111111111112,
      0.0001848888888888889,
      0.00018266666666666667,
      0.00018044444444444447,
      0.00017822222222222222,
      0.00017600000000000002,
      0.0001737777777777778,
      0.00017155555555555555,
      0.00016933333333333335,
      0.00016711111111111112,
      0.0001648888888888889,
      0.00016266666666666667,
      0.00016044444444444445,
      0.00015822222222222222,
      0.00015600000000000002,
      0.00015377777777777777,
      0.00015155555555555557,
      0.00014933333333333335,
      0.00014711111111111112,
      0.0001448888888888889,
      0.00014266666666666667,
      0.00014044444444444445,
      0.00013822222222222222,
      0.00013600000000000003,
      0.00013377777777777777,
      0.00013155555555555558,
      0.00012933333333333332,
      0.00012711111111111113,
      0.0001248888888888889,
      0.00012266666666666668,
      0.00012044444444444445,
      0.00011822222222222224,
      0.000116,
      0.00011377777777777779,
      0.00011155555555555556,
      0.00010933333333333333,
      0.00010711111111111111,
      0.0001048888888888889,
      0.00010266666666666666,
      0.00010044444444444445,
      9.822222222222223e-05,
      9.6e-05,
      9.377777777777779e-05,
      9.155555555555557e-05,
      8.933333333333334e-05,
      8.711111111111112e-05,
      8.488888888888889e-05,
      8.266666666666667e-05,
      8.044444444444444e-05,
      7.822222222222223e-05,
      7.6e-05,
      7.377777777777778e-05,
      7.155555555555555e-05,
      6.933333333333334e-05,
      6.711111111111112e-05,
      6.488888888888889e-05,
      6.266666666666667e-05,
      6.044444444444445e-05,
      5.8222222222222224e-05,
      5.6000000000000006e-05,
      5.377777777777778e-05,
      5.1555555555555556e-05,
      4.933333333333334e-05,
      4.711111111111111e-05,
      4.4888888888888894e-05,
      4.266666666666667e-05,
      4.0444444444444444e-05,
      3.8222222222222226e-05,
      3.6e-05,
      3.377777777777778e-05,
      3.155555555555556e-05,
      2.9333333333333336e-05,
      2.7111111111111114e-05,
      2.488888888888889e-05,
      2.2666666666666668e-05,
      2.0444444444444446e-05,
      1.8222222222222224e-05,
      1.6000000000000003e-05,
      1.3777777777777778e-05,
      1.1555555555555556e-05,
      9.333333333333334e-06,
      7.111111111111112e-06,
      4.888888888888889e-06,
      2.666666666666667e-06,
      4.444444444444445e-07
    ],
    "epochs": [
      0.02,
      0.04,
      0.06,
      0.08,
      0.1,
      0.12,
      0.14,
      0.16,
      0.18,
      0.2,
      0.22,
      0.24,
      0.26,
      0.28,
      0.3,
      0.32,
      0.34,
      0.36,
      0.38,
      0.4,
      0.42,
      0.44,
      0.46,
      0.48,
      0.5,
      0.52,
      0.54,
      0.56,
      0.58,
      0.6,
      0.62,
      0.64,
      0.66,
      0.68,
      0.7,
      0.72,
      0.74,
      0.76,
      0.78,
      0.8,
      0.82,
      0.84,
      0.86,
      0.88,
      0.9,
      0.92,
      0.94,
      0.96,
      0.98,
      1.0,
      1.02,
      1.04,
      1.06,
      1.08,
      1.1,
      1.12,
      1.1400000000000001,
      1.16,
      1.18,
      1.2,
      1.22,
      1.24,
      1.26,
      1.28,
      1.3,
      1.32,
      1.34,
      1.3599999999999999,
      1.38,
      1.4,
      1.42,
      1.44,
      1.46,
      1.48,
      1.5,
      1.52,
      1.54,
      1.56,
      1.58,
      1.6,
      1.62,
      1.6400000000000001,
      1.6600000000000001,
      1.6800000000000002,
      1.7,
      1.72,
      1.74,
      1.76,
      1.78,
      1.8,
      1.8199999999999998,
      1.8399999999999999,
      1.8599999999999999,
      1.88,
      1.9,
      1.92,
      1.94,
      1.96,
      1.98,
      2.0
    ]
  }
}