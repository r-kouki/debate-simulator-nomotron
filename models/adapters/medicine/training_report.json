{
  "timestamp": "2026-01-05T22:53:42.333736",
  "config": {
    "domain": "medicine",
    "base_model": "/home/core/projects/debate-simulator/models/base/llama3.1-nemotron-nano-8b-v1",
    "sft_path": "data/sft/medicine_improved.jsonl",
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05,
    "target_modules": [
      "q_proj",
      "v_proj"
    ],
    "num_epochs": 2,
    "batch_size": 2,
    "gradient_accumulation_steps": 8,
    "learning_rate": 0.0002,
    "max_seq_length": 512,
    "max_train_samples": 4000,
    "max_val_samples": 400,
    "max_test_samples": 200
  },
  "dataset_sizes": {
    "train": 4000,
    "val": 400,
    "test": 200
  },
  "final_metrics": {
    "train_loss": 0.9573034796714782,
    "train_perplexity": 2.60466346737404,
    "val_loss": 0.6454573273658752,
    "val_perplexity": 1.906858888646792,
    "test_loss": 0.6722482442855835,
    "test_perplexity": 1.9586358661744276
  },
  "training_history": {
    "steps": [
      5,
      10,
      15,
      20,
      25,
      30,
      35,
      40,
      45,
      50,
      55,
      60,
      65,
      70,
      75,
      80,
      85,
      90,
      95,
      100,
      105,
      110,
      115,
      120,
      125,
      130,
      135,
      140,
      145,
      150,
      155,
      160,
      165,
      170,
      175,
      180,
      185,
      190,
      195,
      200,
      205,
      210,
      215,
      220,
      225,
      230,
      235,
      240,
      245,
      250,
      255,
      260,
      265,
      270,
      275,
      280,
      285,
      290,
      295,
      300,
      305,
      310,
      315,
      320,
      325,
      330,
      335,
      340,
      345,
      350,
      355,
      360,
      365,
      370,
      375,
      380,
      385,
      390,
      395,
      400,
      405,
      410,
      415,
      420,
      425,
      430,
      435,
      440,
      445,
      450,
      455,
      460,
      465,
      470,
      475,
      480,
      485,
      490,
      495,
      500
    ],
    "training_loss": [
      4.7415,
      4.6431,
      4.3212,
      3.7985,
      3.4326,
      2.7263,
      2.225,
      1.6368,
      1.355,
      1.0842,
      1.0229,
      1.0026,
      0.9392,
      0.9112,
      0.9305,
      0.9125,
      0.8692,
      0.9235,
      0.9237,
      0.8875,
      0.8708,
      0.9366,
      0.8535,
      0.9092,
      0.8735,
      0.8818,
      0.9046,
      0.8274,
      0.8592,
      0.7753,
      0.8473,
      0.847,
      0.7772,
      0.8261,
      0.7688,
      0.7522,
      0.7106,
      0.6928,
      0.7337,
      0.7067,
      0.746,
      0.6516,
      0.6624,
      0.7239,
      0.6895,
      0.7695,
      0.7055,
      0.688,
      0.6973,
      0.7156,
      0.6961,
      0.6472,
      0.6907,
      0.6982,
      0.622,
      0.6622,
      0.6399,
      0.6761,
      0.7039,
      0.6502,
      0.6495,
      0.6748,
      0.6745,
      0.6692,
      0.6124,
      0.693,
      0.635,
      0.6954,
      0.63,
      0.6887,
      0.6601,
      0.6704,
      0.6562,
      0.6865,
      0.642,
      0.6635,
      0.6394,
      0.6079,
      0.6455,
      0.6587,
      0.6518,
      0.6779,
      0.6684,
      0.6746,
      0.6692,
      0.6532,
      0.6291,
      0.665,
      0.6686,
      0.6619,
      0.6669,
      0.674,
      0.6452,
      0.625,
      0.6672,
      0.6402,
      0.6362,
      0.6483,
      0.6892,
      0.6885
    ],
    "validation_loss": [
      3.5512590408325195,
      1.4212355613708496,
      0.9325743317604065,
      0.8780609369277954,
      0.8574501276016235,
      0.8425055146217346,
      0.8212852478027344,
      0.7747535109519958,
      0.7126818299293518,
      0.6878263354301453,
      0.6775270104408264,
      0.6719783544540405,
      0.6688597798347473,
      0.6641821265220642,
      0.661084771156311,
      0.6576992273330688,
      0.6551034450531006,
      0.6534961462020874,
      0.6518383026123047,
      0.6510939598083496,
      0.649391233921051,
      0.6473095417022705,
      0.6466758251190186,
      0.6457991003990173,
      0.6454573273658752,
      0.6454573273658752,
      0.6722482442855835
    ],
    "learning_rate": [
      1.6000000000000003e-05,
      3.6e-05,
      5.6000000000000006e-05,
      7.6e-05,
      9.6e-05,
      0.000116,
      0.00013600000000000003,
      0.00015600000000000002,
      0.00017600000000000002,
      0.000196,
      0.00019822222222222225,
      0.000196,
      0.0001937777777777778,
      0.00019155555555555554,
      0.00018933333333333335,
      0.00018711111111111112,
      0.0001848888888888889,
      0.00018266666666666667,
      0.00018044444444444447,
      0.00017822222222222222,
      0.00017600000000000002,
      0.0001737777777777778,
      0.00017155555555555555,
      0.00016933333333333335,
      0.00016711111111111112,
      0.0001648888888888889,
      0.00016266666666666667,
      0.00016044444444444445,
      0.00015822222222222222,
      0.00015600000000000002,
      0.00015377777777777777,
      0.00015155555555555557,
      0.00014933333333333335,
      0.00014711111111111112,
      0.0001448888888888889,
      0.00014266666666666667,
      0.00014044444444444445,
      0.00013822222222222222,
      0.00013600000000000003,
      0.00013377777777777777,
      0.00013155555555555558,
      0.00012933333333333332,
      0.00012711111111111113,
      0.0001248888888888889,
      0.00012266666666666668,
      0.00012044444444444445,
      0.00011822222222222224,
      0.000116,
      0.00011377777777777779,
      0.00011155555555555556,
      0.00010933333333333333,
      0.00010711111111111111,
      0.0001048888888888889,
      0.00010266666666666666,
      0.00010044444444444445,
      9.822222222222223e-05,
      9.6e-05,
      9.377777777777779e-05,
      9.155555555555557e-05,
      8.933333333333334e-05,
      8.711111111111112e-05,
      8.488888888888889e-05,
      8.266666666666667e-05,
      8.044444444444444e-05,
      7.822222222222223e-05,
      7.6e-05,
      7.377777777777778e-05,
      7.155555555555555e-05,
      6.933333333333334e-05,
      6.711111111111112e-05,
      6.488888888888889e-05,
      6.266666666666667e-05,
      6.044444444444445e-05,
      5.8222222222222224e-05,
      5.6000000000000006e-05,
      5.377777777777778e-05,
      5.1555555555555556e-05,
      4.933333333333334e-05,
      4.711111111111111e-05,
      4.4888888888888894e-05,
      4.266666666666667e-05,
      4.0444444444444444e-05,
      3.8222222222222226e-05,
      3.6e-05,
      3.377777777777778e-05,
      3.155555555555556e-05,
      2.9333333333333336e-05,
      2.7111111111111114e-05,
      2.488888888888889e-05,
      2.2666666666666668e-05,
      2.0444444444444446e-05,
      1.8222222222222224e-05,
      1.6000000000000003e-05,
      1.3777777777777778e-05,
      1.1555555555555556e-05,
      9.333333333333334e-06,
      7.111111111111112e-06,
      4.888888888888889e-06,
      2.666666666666667e-06,
      4.444444444444445e-07
    ],
    "epochs": [
      0.02,
      0.04,
      0.06,
      0.08,
      0.1,
      0.12,
      0.14,
      0.16,
      0.18,
      0.2,
      0.22,
      0.24,
      0.26,
      0.28,
      0.3,
      0.32,
      0.34,
      0.36,
      0.38,
      0.4,
      0.42,
      0.44,
      0.46,
      0.48,
      0.5,
      0.52,
      0.54,
      0.56,
      0.58,
      0.6,
      0.62,
      0.64,
      0.66,
      0.68,
      0.7,
      0.72,
      0.74,
      0.76,
      0.78,
      0.8,
      0.82,
      0.84,
      0.86,
      0.88,
      0.9,
      0.92,
      0.94,
      0.96,
      0.98,
      1.0,
      1.02,
      1.04,
      1.06,
      1.08,
      1.1,
      1.12,
      1.1400000000000001,
      1.16,
      1.18,
      1.2,
      1.22,
      1.24,
      1.26,
      1.28,
      1.3,
      1.32,
      1.34,
      1.3599999999999999,
      1.38,
      1.4,
      1.42,
      1.44,
      1.46,
      1.48,
      1.5,
      1.52,
      1.54,
      1.56,
      1.58,
      1.6,
      1.62,
      1.6400000000000001,
      1.6600000000000001,
      1.6800000000000002,
      1.7,
      1.72,
      1.74,
      1.76,
      1.78,
      1.8,
      1.8199999999999998,
      1.8399999999999999,
      1.8599999999999999,
      1.88,
      1.9,
      1.92,
      1.94,
      1.96,
      1.98,
      2.0
    ]
  }
}